{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sophisticated-flower",
   "metadata": {},
   "source": [
    "# Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beginning-credits",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt # Plotting package\n",
    "from mpl_toolkits.mplot3d import Axes3D # 3D plotting package\n",
    "import numpy as np # Fast array-based computations\n",
    "import pandas as pd # Data manipulation package\n",
    "from scipy import stats # Used for drawing from stats distributions\n",
    "import seaborn as sn # Used for more pretty plotting (but not really necessary)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "painful-cathedral",
   "metadata": {},
   "source": [
    "%matplotlib notebook\n",
    "plt.style.use('seaborn')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arranged-bicycle",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import solve_triangular\n",
    "\n",
    "class GPR:\n",
    "    \"\"\"Gaussian Process regressors can be instantiated and sampled from\n",
    "    using this class. The code is based on Algorithm 2.1 from Rasmussen \n",
    "    and Williams' Gaussian process regression book.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel=None, noise_level=0.00005):\n",
    "        \"\"\"Must provide the kernel function and a noise_level. The kernel\n",
    "        function should take two inputs and return a covariance matrix \n",
    "        between those inputs. The noise_level describes how noisy we think \n",
    "        the input data is. A noise level of 0 will cause the GP to exactly \n",
    "        interpolate the data points, unless you account for the noise in\n",
    "        your kernel function.\n",
    "        \"\"\"\n",
    "        # Use the default kernel if not provided.\n",
    "        if kernel is None: kernel = self.rbf_kernel   \n",
    "\n",
    "        self.kernel = kernel\n",
    "        self.noise_level = noise_level\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def rbf_kernel(x1,x2,sig=1.0):\n",
    "        \"\"\"The RBF kernel (squared exponential distance).\"\"\"\n",
    "        sqdist = np.linalg.norm(x1[:,np.newaxis] - x2, axis=-1)**2\n",
    "        return np.exp( -sqdist / (2*sig**2))\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Trains the Gaussian process by finding the internal parameters K, \n",
    "        L.\n",
    "        \"\"\"\n",
    "        # Take the output mean so we can normalize our GP's output.\n",
    "        self.mu_hat = y.mean()\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y - self.mu_hat # Now the y's have sample mean 0.\n",
    "        K = self.kernel(X, X)\n",
    "        self.L = np.linalg.cholesky(K + self.noise_level*np.eye(len(X)))\n",
    "        temp = solve_triangular(self.L, self.y, lower=True)\n",
    "        self.alpha = solve_triangular(self.L.T, temp)\n",
    "        \n",
    "        \n",
    "    def predict(self, x_star, return_std=False):\n",
    "        \"\"\"Returns the mean of the GP at x_star. Can also return the standard\n",
    "        deviation at each of those points if desired. Note that the standard\n",
    "        deviation calculations are the most performance-intensive aspect\n",
    "        of this function.\n",
    "        \"\"\"        \n",
    "        # Compute the mean at the test points.\n",
    "        k_star = self.kernel(self.X, x_star)\n",
    "        mu = k_star.T @ self.alpha\n",
    "        mu += self.mu_hat # So that the output has the correct sample mean.\n",
    "        \n",
    "        # Compute the standard deviation.\n",
    "        if return_std:\n",
    "            v = solve_triangular(self.L, k_star, lower=True)\n",
    "            # We take np.diag in the following line to discard covariances.\n",
    "            std = np.sqrt(np.diag(self.kernel(x_star, x_star) - v.T @ v))\n",
    "            return mu, std\n",
    "        \n",
    "        return mu\n",
    "    \n",
    "    \n",
    "    def llh(self):\n",
    "        \"\"\"Returns the log-likelihood of the trained GPR.\"\"\"\n",
    "        llh = -0.5*self.y.T @ self.alpha \n",
    "        llh -= np.sum(np.log(np.diag(self.L))) \n",
    "        llh -= len(self.L)/2*np.log(2*np.pi)\n",
    "        return llh\n",
    "    \n",
    "\n",
    "# Create the multiclass model\n",
    "class multid_GPR:\n",
    "    def __init__(self, gprs):\n",
    "        \"\"\"Initialize a list of gprs.\"\"\"\n",
    "        self.gprs = gprs\n",
    "    \n",
    "    def predict(self, X, return_std=False):\n",
    "        \n",
    "        out = []\n",
    "        for gpr in self.gprs:\n",
    "            out.append(gpr.predict(X,return_std=False))\n",
    "        \n",
    "        return np.array(out)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "healthy-pharmaceutical",
   "metadata": {},
   "source": [
    "### Constructing a Model\n",
    "\n",
    "First, we must find a model whose sensitivity we care about. \n",
    "Ideally, this model will be nonlinear, but not take too much time to find solutions to. \n",
    "For this example, the model we will use is a Gaussian process regressor that models parameters of an underwater fault line.\n",
    "The model takes two inputs: latitude and longitude. \n",
    "It outputs 3 desired quantities: depth, strike, and dip.\n",
    "Depth represents the depth of the seafloor below sea level, and strike and dip are angles that describe the geometry of the fault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "competent-delight",
   "metadata": {},
   "source": [
    "import cartopy # Mapping package\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# TsunamiBayes is a package we've created in my research.\n",
    "# It utilizes Bayesian methods to predict past Tsunamis based on historical data.\n",
    "import tsunamibayes as tb\n",
    "from tsunamibayes.fault import ReferenceCurveFault, BaseFault\n",
    "from tsunamibayes.multifault import MultiFault\n",
    "from tsunamibayes.utils import bearing, haversine"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "professional-search",
   "metadata": {},
   "source": [
    "from sensitivity_data_loader import load_data\n",
    "\n",
    "lats, lons, depths, dips, strikes, rakes = load_data()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "personalized-czech",
   "metadata": {},
   "source": [
    "Save the Flores data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "applied-elevation",
   "metadata": {},
   "source": [
    "np.savez('flores_data', lats=lats, lons=lons, depths=depths, dips=dips, strikes=strikes, rakes=rakes)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "optional-intro",
   "metadata": {},
   "source": [
    "#### Fit a Gaussian Process to Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alternative-order",
   "metadata": {},
   "source": [
    "# Get data for plotting\n",
    "plotting_lats = np.linspace(-9, -8, 100)\n",
    "plotting_lons = np.linspace(115, 127, 100)\n",
    "Xplot, Yplot = np.meshgrid(plotting_lons,plotting_lats)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "introductory-hampshire",
   "metadata": {},
   "source": [
    "# Get data for fitting the GP\n",
    "X = np.vstack([lats, lons]).T\n",
    "y = depths.copy()\n",
    "ker = lambda x,y: GPR.rbf_kernel(x,y,sig=0.25)\n",
    "depth_gpr = GPR(kernel=ker, noise_level=1.0)\n",
    "\n",
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "depth_gpr.fit(X, y)\n",
    "Zplot,sigma = depth_gpr.predict(np.vstack([Yplot.flatten(), Xplot.flatten()]).T, return_std=True)\n",
    "Zplot = Zplot.reshape(Xplot.shape)\n",
    "#sigma = sigma.reshape(Xplot.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Plot original Flores-associated lat/lon depths\n",
    "ax.scatter(X[:,1], X[:,0], y, c='r', s=20)\n",
    "ax.plot_surface(Xplot,Yplot,Zplot,cmap='viridis')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude'),\n",
    "ax.set_zlabel('Depth')\n",
    "plt.title('Depth Regression Using Gaussian Process')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "conceptual-jackson",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Plot original Flores-associated lat/lon depths\n",
    "ax.scatter(X[:,1], X[:,0], y, c='r', s=20)\n",
    "#ax.plot_surface(Xplot,Yplot,Zplot,cmap='viridis')\n",
    "ax.set_xlabel('Longitude (degrees)')\n",
    "ax.set_ylabel('Latitude (degrees)'),\n",
    "ax.set_zlabel('Depth (km)')\n",
    "plt.title('Flores Fault Depth Data')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "natural-preliminary",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Plot original Flores-associated lat/lon depths\n",
    "ax.scatter(X[:,1], X[:,0], y, c='r', s=20)\n",
    "ax.plot_surface(Xplot,Yplot,Zplot,cmap='viridis')\n",
    "ax.set_xlabel('Longitude (degrees)')\n",
    "ax.set_ylabel('Latitude (degrees)'),\n",
    "ax.set_zlabel('Depth (km)')\n",
    "plt.title('Depth Regression Using Gaussian Process')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "innocent-percentage",
   "metadata": {},
   "source": [
    "sigma = sigma.reshape(Xplot.shape)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Plot original Flores-associated lat/lon depths\n",
    "ax.scatter(X[:,1], X[:,0], y, c='r', s=20)\n",
    "#ax.plot_surface(Xplot,Yplot,Zplot,cmap='viridis')\n",
    "ax.plot_surface(Xplot,Yplot,Zplot+4*sigma, cmap='Purples')\n",
    "ax.plot_surface(Xplot,Yplot,Zplot-4*sigma, cmap='Purples')\n",
    "ax.set_xlabel('Longitude (degrees)')\n",
    "ax.set_ylabel('Latitude (degrees)'),\n",
    "ax.set_zlabel('Depth (km)')\n",
    "plt.title('Depth Regression with 2 Standard Deviation Regions')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "matched-dublin",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "plt.plot(Xplot[50],Zplot[50],'--')\n",
    "plt.gca().fill_between(\n",
    "    Xplot[50], \n",
    "    Zplot[50]-4*sigma[50], \n",
    "    Zplot[50]+4*sigma[50], \n",
    "    color=\"#dddddd\"\n",
    ")\n",
    "mask = np.abs(X[:,0] - Yplot[50][0]) < 0.05\n",
    "plt.scatter(X[:,1][mask], y[mask],c='r')\n",
    "plt.title('Gaussian Process Slice at Latitude -8.5 degrees')\n",
    "plt.xlabel('Longitude (degrees)')\n",
    "plt.ylabel('Depth (km)')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "chinese-giving",
   "metadata": {},
   "source": [
    "\n",
    "X[:,0][mask]\n",
    "X[:,1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "moving-formula",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "foreign-stationery",
   "metadata": {},
   "source": [
    "y"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "regulation-fabric",
   "metadata": {},
   "source": [
    "n = 4\n",
    "print(Zplot[0,:n])\n",
    "Zplot_test, Zplot_std_test = depth_gpr.predict(np.vstack([Yplot.flatten()[:n], Xplot.flatten()[:n]]).T, return_std=True)\n",
    "print(Zplot_test)\n",
    "print(Zplot_std_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rubber-hepatitis",
   "metadata": {},
   "source": [
    "np.vstack([Yplot.flatten()[:n], Xplot.flatten()[:n]]).T.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "pregnant-tuesday",
   "metadata": {},
   "source": [
    "np.vstack([10, 15]).T"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "right-tackle",
   "metadata": {},
   "source": [
    "print(Zplot[0,:5])\n",
    "Zplot_test2, Zplot_std_test2 = depth_gpr.predict(np.vstack([Yplot.flatten()[:5], Xplot.flatten()[:5]]).T, return_std=True)\n",
    "print(Zplot_test2)\n",
    "print(Zplot_std_test2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cellular-glory",
   "metadata": {},
   "source": [
    "# Get data for fitting the GP\n",
    "X = np.vstack([lats, lons]).T\n",
    "y = dips.copy()\n",
    "ker = lambda x,y: GPR.rbf_kernel(x,y,sig=0.75)\n",
    "dip_gpr = GPR(kernel=ker, noise_level=1)\n",
    "\n",
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "dip_gpr.fit(X, y)\n",
    "Zplot = dip_gpr.predict(np.vstack([Yplot.flatten(), Xplot.flatten()]).T, return_std=False)\n",
    "Zplot = Zplot.reshape(Xplot.shape)\n",
    "#sigma = sigma.reshape(Xplot.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Plot original Flores-associated lat/lon depths\n",
    "ax.scatter(X[:,1], X[:,0], y, c='r', s=20)\n",
    "ax.plot_surface(Xplot,Yplot,Zplot,cmap='viridis')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_zlabel('Dip')\n",
    "plt.title('Dip Regression Using Gaussian Process')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "computational-personal",
   "metadata": {},
   "source": [
    "# Get data for fitting the GP\n",
    "X = np.vstack([lats, lons]).T\n",
    "y = strikes.copy()\n",
    "ker = lambda x,y: GPR.rbf_kernel(x,y,sig=0.75)\n",
    "strike_gpr = GPR(kernel=ker, noise_level=1)\n",
    "\n",
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "strike_gpr.fit(X, y)\n",
    "Zplot = strike_gpr.predict(np.vstack([Yplot.flatten(), Xplot.flatten()]).T, return_std=False)\n",
    "Zplot = Zplot.reshape(Xplot.shape)\n",
    "#sigma = sigma.reshape(Xplot.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Plot original Flores-associated lat/lon depths\n",
    "ax.scatter(X[:,1], X[:,0], y, c='r', s=20)\n",
    "ax.plot_surface(Xplot,Yplot,Zplot,cmap='viridis')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_zlabel('Strike')\n",
    "plt.title('Strike Regression Using Gaussian Process')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "built-tolerance",
   "metadata": {},
   "source": [
    "gpr = multid_GPR([depth_gpr, dip_gpr, strike_gpr])\n",
    "Xtest = np.vstack([Yplot.flatten(), Xplot.flatten()]).T\n",
    "preds = gpr.predict(Xtest)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-discussion",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
